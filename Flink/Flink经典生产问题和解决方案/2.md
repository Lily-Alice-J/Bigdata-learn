##问题一

    org.apache.flink.util.FlinkException: 
    The assigned slot container_e08_1539148828017_15937_01_003564_0 was removed. 
     at org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager.removeSlot(SlotManager.java:786)
     at org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager.removeSlots(SlotManager.java:756) 
     at org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager.internalUnregisterTaskManager(SlotManager.java:948)
     at org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager.unregisterTaskManager(SlotManager.java:372) 
     at org.apache.flink.runtime.resourcemanager.ResourceManager.closeTaskManagerConnection(ResourceManager.java:803) 
     at org.apache.flink.yarn.YarnResourceManager.lambda$onContainersCompleted$0(YarnResourceManager.java:340) 
     at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:332) 
     at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:158) 
     at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:70) 
     at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.onReceive(AkkaRpcActor.java:142)
    
    程序内存占用过大，导致TaskManager在yarn上kill了，分析原因应该是资源不够，可以将程序放在资源更大的集群上，再不行就设置减少Slot中共享的task的个数，也可能是内存泄露或内存资源配置不合理造成，需要进行合理分配。
    
    
 ##问题二
 
    The heartbeat of TaskManager with id container ....... timed out
    Caused by: java.util.concurrent.CompletionException: akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka.tcp://flink@flink88:15265/user/taskmanager_0#6643546564]] after [10000 ms]. Sender[null] sent message of type "org.apache.flink.runtime.rpc.messages.RemoteRpcInvocation".
    
    1、分布式物理机网络失联，这种原因一般情况下failover后作业能正常恢复，如果出现的不频繁可以不用关注；
    2、failover的节点对应TM的内存设置太小，GC严重导致心跳超时，建议调大对应节点的内存值。
    3.在flink-conf.yaml中添加或修改：akka.ask.timeout: 100s web.timeout: 100000。
    
##问题三

    Checkpoint：Checkpoint expired before completing
    
    checkpointConf.setCheckpointTimeout(5000L)这个值设置过小，默认是10min，需要进行调大测试。
    
##问题四

    Kafka partition leader切换导致Flink重启
    java.lang.Exception: Failed to send data to Kafka: 
    This server is not the leader for that topic-partition.
     at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.checkErroneous(FlinkKafkaProducerBase.java:373) 
     at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.invoke(FlinkKafkaProducerBase.java:280) 
     at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:41)
     at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:206)
     at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:69) 
     at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:263) 
     at org.apache.flink.runtime.taskmanager.Task.run(Task.java:702) 
     at java.lang.Thread.run(Thread.java:748) 
     Caused by: org.apache.kafka.common.errors.NotLeaderForPartitionException: 
     This server is not the leader for that topic-partition.
     
     查看Kafka的Controller日志，显示：
     INFO [SessionExpirationListener on 10], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
     关于producer参数设置，设置retries参数，可以在Kafka的Partition发生leader切换时，Flink不重启，而是做3次尝试：
     kafkaProducerConfig
               {
                     "bootstrap.servers": "192.169.2.20:9093,192.169.2.21:9093,192.169.2.22:9093"
                     "retries":3
               }
               