## 1.数据倾斜导致子任务积压

### 业务背景：

    一个流程中，有两个重要子任务：一是数据迁移，将kafka实时数据落Es，二是将kafka数据做窗口聚合落hbase，两个子任务接的是同一个Topic GroupId。上游Topic的 tps高峰达到5-6w。
    
### 问题描述：
    
    给 24个 TaskManager(CPU) 都会出现来不及消费的情况。
    
### 问题原因：

    做窗口聚合的任务的分组字段，分组粒度太小，hash不能打散，数据倾斜严重，导致少数TaskManager上压力过大，从而影响落Es的效率，导致背压。
    
### 解决方式：

    将两个任务独立开来，作为不同的流程。
    
### 结果：

    修改之前24个TaskManager(CPU) 来不及消费，改完之后20个CPU可完成任务。Kafka实时数据落Es的16个TaskManager，将kafka数据做窗口聚合落hbase的4个TaskManager。
    另：同样的数据、同样的Tps作为数据输入，Hbase的输出能力远超过Es，考虑实时任务落数据进Es要慎重。Flink任务落Es时要考虑设置微批落数据，设置bulk.flush.max.actions和bulk.flush.interval.ms至合适值，否则影响吞吐量。
    
    
    
## 2.Kafka消息大小默认配置太小，导致数据未处理

### 业务背景：

    正常的Flink任务消费Topic数据，但是Topic中的数据为XML以及JSON，单条数据较大。
    
### 问题描述：

    Flink各项metrics指标正常，但是没处理到数据。
    
### 问题原因：
    
    Topic中单条数据> 1M，超过Kafka Consumer处理单条数据的默认最大值。
    
### 解决方式：

    有三种可选方式：扩大kafka consumer单条数据的数据大小：fetch.message.max.bytes。
                  对消息进行压缩：上游kafka producer设置compression.codec和commpressed.topics。
                  业务上对数据切片，在上游kafka producer端将数据切片为10K，使用分区主键确保同一条数据发送到同一Partition，consumer对消息重组。
                  
### 结果：

    方式一：按业务要求扩大Kafka Consumer可处理的单条数据字节数即可正常处理业务。
    方式二：Kafka Consumer需先解码，再进行业务处理。
    方式三：Kafka Consumer 需先重组数据，再进行业务处理。
    
    
