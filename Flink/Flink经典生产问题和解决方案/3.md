## 注意mapWithState & TTL的重要性

    在处理包含无限多键的数据时，要考虑到keyed状态保留策略（通过TTL定时器来在给定的时间之后清理未使用的数据）是很重要的。术语『无限』在这里有点误导，因为如果你要处理的key以128位编码，则key的最大数量将会有个限制（等于2的128次方）。但这是一个巨大的数字！你可能无法在状态中存储那么多值，所以最好考虑你的键空间是无界的，同时新键会随着时间不断出现。 
    如果你的keyed状态包含在某个Flink的默认窗口中，则将是安全的：即使未使用TTL，在处理窗口的元素时也会注册一个清除计时器，该计时器将调用clearAllState函数，并删除与该窗口关联的状态及其元数据。  
    如果要使用Keyed State Descriptor来管理状态，可以很方便地添加TTL配置，以确保在状态中的键数量不会无限制地增加。 
    但是，你可能会想使用更简便的mapWithState方法，该方法可让你访问valueState并隐藏操作的复杂性。虽然这对于测试和少量键的数据来说是很好的选择，但如果在生产环境中遇到无限多键值时，会引发问题。由于状态是对你隐藏的，因此你无法设置TTL，并且默认情况下未配置任何TTL。这就是为什么值得考虑做一些额外工作的原因，如声明诸如RichMapFunction之类的东西，这将使你能更好的控制状态的生命周期。
    

## 部署和资源问题
    
    (0) JDK版本过低
    
    这不是个显式错误，但是JDK版本过低很有可能会导致Flink作业出现各种莫名其妙的问题，因此在生产环境中建议采用JDK8的较高update（我们使用的是181）。
    
    (1) Could not build the program from JAR file
    
    该信息不甚准确，因为绝大多数情况下都不是JAR包本身有毛病，而是在作业提交过程中出现异常退出了。因此需要查看本次提交产生的客户端日志（默认位于$FLINK_HOME/logs目录下），再根据其中的信息定位并解决问题。
    
    (2)ClassNotFoundException/NoSuchMethodError/IncompatibleClassChangeError/...
    
    一般都是因为用户依赖第三方包的版本与Flink框架依赖的版本有冲突导致。
    
    (3) Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster
    
    就是字面意思，YARN集群内没有足够的资源启动Flink作业。检查一下当前YARN集群的状态、正在运行的YARN App以及Flink作业所处的队列，释放一些资源或者加入新的资源。
    
    (4) java.util.concurrent.TimeoutException: Slot allocation request timed out
    
    slot分配请求超时，是因为TaskManager申请资源时无法正常获得，按照上一条的思路检查即可。
    
    (5) org.apache.flink.util.FlinkException: The assigned slot < container_id> was removed
    
    TaskManager的Container因为使用资源超限被kill掉了。首先需要保证每个slot分配到的内存量足够，特殊情况下可以手动配置SlotSharingGroup来减少单个slot中共享Task的数量。如果资源没问题，那么多半就是程序内部发生了内存泄露。建议仔细查看TaskManager日志，并按处理JVM OOM问题的常规操作来排查。
    
    (6)java.util.concurrent.TimeoutException: Heartbeat of TaskManager with id < tm_id>timed out
    
    TaskManager心跳超时。有可能是TaskManager已经失败，如果没有失败，那么有可能是因为网络不好导致JobManager没能收到心跳信号，或者TaskManager忙于GC，无法发送心跳信号。JobManager会重启心跳超时的TaskManager，如果频繁出现此异常，应该通过日志进一步定位问题所在。
    
    在Flink中，资源的隔离是通过Slot进行的，也就是说多个Slot会运行在同一个JVM中，这种隔离很弱，尤其对于生产环境。Flink App上线之前要在一个单独的Flink集群上进行测试，否则一个不稳定、存在问题的Flink App上线，很可能影响整个Flink集群上的App。
    
    (7)资源不足导致container被kill
    
    The assigned slot container_container编号 was removed.Flink App 抛出此类异常，通过查看日志，一般就是某一个 Flink App 内存占用大，导致 TaskManager（在 Yarn 上就是 Container ）被Kill 掉。
    
    但是并不是所有的情况都是这个原因，还需要进一步看 yarn 的日志（ 查看 yarn 任务日志：yarn logs -applicationId -appOwner），如果代码写的没问题，就确实是资源不够了，其实1G Slot跑多个Task（Slot Group Share ）其实挺容易出现的。
    
    因此有两种选择，可以根据具体情况，权衡选择一个。
    
    将该Flink App调度在Per slot内存更大的集群上。通过slotSharingGroup("xxx") ，减少Slot中共享Task的个数
    
    (8)启动报错，提示找不到 jersey 的类
    
    java.lang.NoClassDefFoundError:com/sun/jersey/core/util/FeaturesAndProperties 解决办法进入 yarn中 把 lib 目中的一下两个问价拷贝到flink的lib中hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar /hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar
    
    (9)Scala版本冲突
    
    java.lang.NoSuchMethodError:scala.collection.immutable.HashSet$.empty()Lscala/collection/
    解决办法，添加: import org.apache.flink.api.scala._
    
    (10)没有使用回撤流报错
    
    Table is not an append一only table. Use the toRetractStream() in order to handle add and retract messages.
    这个是因为动态表不是 append-only 模式的，需要用 toRetractStream ( 回撤流) 处理就好了.
    
    (11)OOM 问题解决思路
    
    java.lang.OutOfMemoryError: GC overhead limit exceeded java.lang.OutOfMemoryError: GC overhead limit exceeded at java.util.Arrays.copyOfRange(Arrays.java:3664) at java.lang.String.(String.java:207) at com.esotericsoftware.kryo.io.Input.readString(Input.java:466) at com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.read(DefaultSerializers.java:177)......at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:524)
    解决方案：
    检查slot槽位够不够或者slot分配的数量有没有生效。程序起的并行是否都正常分配了(会有这样的情况出现,假如5个并行,但是只有2个在几点上生效了,另外3个没有数据流动)。检查flink程序有没有数据倾斜，可以通过flink的ui界面查看每个分区子节点处理的数据量。
    
    (12)解析返回值类型失败报错
    
    The return type of function could not be determined automatically Exception 
    in thread "main" org.apache.flink.api.common.functions.InvalidTypesException: 
    The return type of function 'main(RemoteEnvironmentTest.java:27)' could not be determined automatically, due to type erasure. 
    You can give type information hints by using the returns(...) method on the result of the transformation call, 
    or by letting your function implement the 'ResultTypeQueryable' interface. 
    at org.apache.flink.api.java.DataSet.getType(DataSet.java:178) 
    at org.apache.flink.api.java.DataSet.collect(DataSet.java:410) 
    at org.apache.flink.api.java.DataSet.print(DataSet.java:1652)
    
    解决方案：产生这种现象的原因一般是使用lambda表达式没有明确返回值类型，或者使用特使的数据结构flink无法解析其类型，这时候我们需要在方法的后面添加返回值类型，比如字符串。
    
    (13)Hadoop jar 包冲突
    
    Caused by: java.io.IOException: 
    The given file system URI (hdfs:///data/checkpoint-data/abtest) did not describe the authority (like for example HDFS NameNode address/port or S3 host). 
    The attempt to use a configured default authority failed: Hadoop configuration did not contain an entry for the default file system ('fs.defaultFS'). 
    at org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.create(HadoopFsFactory.java:135) at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:399) 
    at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:318) 
    at org.apache.flink.core.fs.Path.getFileSystem(Path.java:298)
    
    解决：pom文件中去掉和hadoop相关的依赖就好了。