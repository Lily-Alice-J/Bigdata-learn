3.1 Standalone 模式

3.1.1 安装

解压缩 flink-1.7.2-bin-hadoop27-scala_2.11.tgz，进入 conf 目录中。

1 ）修改 flink/conf/flink-conf.yaml 文件：
    
    jobmanager.rpc.address=bigData
    
2 ）修改 /conf/slave 文件：

    hadoop1
    hadoop2
    
3 ）分发给另外两台机子：

    xsync flink-1.7.0
4 ）启动：

    ./bin/start-cluster.sh
    
访问 http://localhost:8081 可以对 flink 集群和任务进行监控管理。

-----------------------------------------------------------------

3.2 Yarn 模式

以 Yarn 模式部署 Flink 任务时，要求 Flink 是有 Hadoop 支持的版本，Hadoop环境需要保证版本在 2.2 以上，并且集群中安装有 HDFS 服务。

1)启动 hadoop 集群（略）

2)启动yarn-session

    ./yarn-session.sh -n 2 -s 2 -jm 1024 -tm 1024 -nm test -d
        
其中：
-n(--container)：TaskManager 的数量。
-s(--slots)： 每个 TaskManager 的 slot 数量，默认一个 slot 一个 core，默认每个
taskmanager 的 slot 的个数为 1，有时可以多一些 taskmanager，做冗余。
-jm：JobManager 的内存（单位 MB)。
-tm：每个 taskmanager 的内存（单位 MB)。
-nm：yarn 的 appName(现在 yarn 的 ui 上的名字)。
-d：后台执行。

----------------------------------------------------------------

3.3 Kubernetes 部署
容器化部署时目前业界很流行的一项技术，基于 Docker 镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是 Kubernetes
（k8s），而 Flink 也在最近的版本中支持了 k8s 部署模式。

1 ） 搭建 Kubernetes 集群（略）

2 ） 配置各组件的 yaml 文件

在 k8s 上构建 Flink Session Cluster，需要将 Flink 集群的组件对应的 docker 镜像
分别在 k8s 上启动，包括 JobManager、TaskManager、JobManagerService 三个镜像
服务。每个镜像服务都可以从中央镜像仓库中获取。

3 ）启动 Flink Session Cluster

// 启动 jobmanager-service 服务

    kubectl create -f jobmanager-service.yaml
    
// 启动 jobmanager-deployment 服务

    kubectl create -f jobmanager-deployment.yaml

// 启动 taskmanager-deployment 服务

    kubectl create -f taskmanager-deployment.yaml
    
4 ）访问 Flink UI 页面

集群启动后，就可以通过 JobManagerServicers 中配置的 WebUI 端口，用浏览器
输入以下 url 来访问 Flink UI 页面了：

http://{JobManagerHost:Port}/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy