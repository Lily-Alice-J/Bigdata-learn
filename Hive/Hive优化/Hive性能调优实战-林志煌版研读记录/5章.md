## 5章

### 一、MapReduce整体处理过程

![image](https://github.com/Tandoy/Bigdata-learn/blob/master/Hive/images/MapReduce整体处理过程.png)

### 二、MapReduce作业输入

#### 1.InputFormat在Hive中的使用

    **在Hive中配置“set mapred.map.tasks=task数量”无法控制Map的任务数**
    （1）在默认情况下Map的个数defaultNum=目标文件或数据的总大小totalSize/hdfs集群文件块的大小blockSize。
    （2）当用户指定mapred.map.tasks，即为用户期望的Map大小，用expNum表示，这个期望值计算引擎不会立即采纳，它会获取apred.map.tasks与defaultNum的较大值，用expMaxNum表示，作为待定选项。
    （3）获取文件分片的大小和分片快大小为参数mapred.min.split.size和blockSize间的较大值，用splitMaxSize表示，将目标文件或数据的总大小除以splitMaxSize即为真实的分片个数，用realSplitNum表示。
    （4）获取realSplitNum与expMaxNum较小值则为实际的Map个数。
    
     defaultNum=totalSize/blockSize
     expNum=mapred.map.tasks
     expMaxNum=max(expNum,defaultNum)
     splitMaxSize=totalSize/max(mapred.min.split.size,blockSize)
     实际的map个数=min(realSplitNum, expMaxNum)
     
     通过上面的逻辑知道：
     ·减少Map个数，需要增大mapred.min.split.size的值，减少mapred.map.tasks的值；
     ·增大Map个数，需要减少mapred.min.split.size的值，同时增大mapred.map.tasks的值。
     
#### 1.Mapper

    1.hive.vectorized.execution.enabled：表示是否开启向量模式，默认值为false。在run（）方法中，我们看到map（）方法是逐行处理数据，这样
    的操作容易产生更多的CPU指令和CPU上下文切换，导致系统的处理性能不高。在关系型数据库里可以采用批量的操作方式避免单行处理数据导致系统处理性能的降低，Hive也提供了类似的功
    能使用向量的模式，将一次处理一条数据变为一次处理1万条数据，来提高程序的性能。
    
    2.hive.auto.convert.join：是否开启MapJoin自动优化，hive 0.11版本以前默认关闭，0.11及以后的版本默认开启
    
    3.hive.map.aggr：是否开启Map任务的聚合，默认值是true。
    
    4.hive.map.aggr.hash.percentmemory：默认值是0.5，表示开启Map任务的聚合，聚合所用的哈希表，所能占用到整个Map被分配的内存50%。例如，Map任务被分配2GB内存，那么哈希表最多只能用1GB。
    
    5.hive.mapjoin.optimized.hashtable：默认值是true，Hive 0.14新增，表示使用一种内存优化的哈希表去做MapJoin。由于该类型的哈希表无法被序列化到磁盘，因此该配置只能用于Tez或者Spark。
    
    6.hive.mapjoin.optimized.hashtable.wbsize：默认值是10485760（10MB），优化的哈希表使用的是一种链块的内存缓存，该值表示一个块的内存缓存大小。这种结构对于数据相对较大的表能够加快数据加载，但是对于数据量较小的表，将会分配多余的内存。
    
    7.hive.map.groupby.sorted：在Hive 2.0以前的默认值是False，2.0及2.0以后的版本默认值为true。对于分桶或者排序表，如果分组聚合的键（列）和分桶或者排序的列一致，将会使用BucketizedHiveInputFormat。
    
    8.hive.vectorized.execution.mapjoin.native.enabled：是否使用原生的向量化执行模式执行MapJoin，它会比普通MapJoin速度快。默认值为False。
    
    9.hive.vectorized.execution.mapjoin.minmax.enabled：默认值为False，是否使用vector map join哈希表，用于整型连接的最大值和最小值过滤。
    
#### 2.Reducer

    hive.multigroupby.singlereducer：表示如果一个SQL语句中有多个分组聚合操作，且分组是使用相同的字段，那么这些分组聚合操作可以用一个作业的Reduce完成，而不是分解成多个作业、多个Reduce完成。这可以减少作业重复读取和Shuffle的操作。
    hive.mapred.reduce.tasks.speculative.execution：表示是否开启Reduce任务的推测执行。即系统在一个Reduce任务中执行进度远低于其他任务的执行进度，会尝试在另外的机器上启动一个相同的Reduce任务。
    hive.optimize.reducededuplication：表示当数据需要按相同的键再次聚合时，则开启这个配置，可以减少重复的聚合操作。
    hive.vectorized.execution.reduce.enabled：表示是否启用Reduce任务的向量化执行模式，默认是true。MapReduce计算引擎并不支持对Reduce阶段的向量化处理。
    hive.vectorized.execution.reduce.groupby.enabled：表示是否移动Reduce任务分组聚合查询的向量化模式，默认值为trueMapReduce计算引擎并不支持对Reduce阶段的向量化处理。

#### 3.Shuffle

    Spark引擎2.0采用Sort BasedShuffle，废弃Hash Based Shuffle
    
#### 4.Map端聚合

    hive.groupby.mapaggr.checkinterval：默认值是100000。Hive在启用Combiner时会尝试取这个配置对应的数据量进行聚合，将聚合后的数据除以聚合前的数据，如果小于hive.map.aggr.hash.min.reduction会自动关闭。
    hive.map.aggr.hash.percentmemory：默认值是0.5。该值表示在进行Mapper端的聚合运行占用的最大内存。例如，分配给该节点的最大堆
    （xmx）为1024MB，那么聚合所能使用的最大Hash表内存是512MB，如果资源较为宽裕，可以适当调节这个参数。
    hive.map.aggr.hash.force.flush.memory.threshold：默认值是0.9。该值表示当在聚合时，所占用的Hash表内存超过0.9，将触发Hash表刷写磁盘的操作。例如Hash表内存是512MB，当Hash表的数据内存超过461MB时将触发Hash表写入到磁盘的操作。

    
#### 5.MapReduce作业与Hive配置

    hive.exec.parallel：默认值是False，是否开启作业的并行。默认情况下，如果一个SQL被拆分成两个阶段，如stage1、stage2，假设这两个stage没有直接的依赖关系，还是会采用窜行的方式依次执行两个阶段。如果开启该配置，则会同时执行两个阶段。在资源较为充足的情况下开启该配置可以有效节省作业的运行时间。
    hive.exec.mode.local.auto：默认值是false，表示是否开启本地的执行模式。开启该配置表示Hive会在单台机器上处理完所有的任务，对于处理数据量较少的任务可以有效地节省时间。开启本地模式还需要以下几个配置帮助。
    hive.optimize.correlation：默认值为false，这个配置我们称之为相关性优化，打开该配置可以减少重复的Shuffle操作。