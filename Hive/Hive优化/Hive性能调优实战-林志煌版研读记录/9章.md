##9章（数据存储）

###一、ORC

    1.ORC存储的文件是一种带有模式描述的行列式存储文件。ORC有别于传统的数据存储文件，它会将数据先按行组进行切分，一个行组内部包含若干行，每一行组再按列进行存储
    
 ![image](https://github.com/Tandoy/Bigdata-learn/blob/master/Hive/images/ORC%E7%9A%84%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png)





###二、Parquet

    1.Parquet是另外的一种高性能行列式的存储结构，可以适用多种计算框架，被多种查询引擎所支持，包括Hive、Impala、Drill等。

![image](https://github.com/Tandoy/Bigdata-learn/blob/master/Hive/images/Parquet%E7%9A%84%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

###三、数据归档

    1.对于HDFS中有大量小文件的表，可以通过Hadoop归档（Hadoop archive）的方式将文件归并成几个较大的文件。归并后的分区会先创建一个data.har目录，里面包含两部分内容：索引（_index和_masterindex）和数据（part-*）。其中，索引记录归并前的文件在归并后的所在位置。
    2.--启用数据归档
      set hive.archive.enabled=true;
      set hive.archive.har.parentdir.settable=true;
      --归档后的最大文件大小
      set har.partfile.size=1099511627776;
      --对分区执行归档的命令
      alter table tablename archive partition（partition_col=partition_val）
      --将归档的分区还原成原来的普通分区
      alter table tablename unarchive partition（partition_col=partition_val）

    
