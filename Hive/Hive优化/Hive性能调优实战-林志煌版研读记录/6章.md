##6章

###一、查看SQL的执行计划

    ·查看执行计划的基本信息，即explain；
    ·查看执行计划的扩展信息（抽象语法树），即explain extended； 
    ·查看SQL数据输入依赖的信息（数据来源表分区），即explain dependency；
    ·查看SQL操作相关权限的信息，即explain authorization；
    ·查看SQL的向量化描述信息，即explain vectorization。
    
###二、具体执行计划解读

以某段sql执行计划为例：
    
    STAGE DEPENDENCIES: // 描绘了作业之间的依赖关系
    Stage-1 is a root stage
    Stage-0 depends on stages: Stage-1
    
    STAGE PLANS: // 每个stage的详细信息
    	  Stage: Stage-1
    	    Map Reduce // 表示当前任务执行所用的计算引擎是MapReduce
    	      Map Operator Tree: // 表示当前描述的Map阶段执行的操作信息
    		  // 表示对关键字alias声明的结果集，这里指代dwd_card_apma_cu，进行表扫描操作
              TableScan
              // alias表示遍历表的别名，在HDFS的数据存储中，实际对应的是一个目录
                alias: dwd_card_apma_cu
                filterExpr: (((datediff(from_unixtime(unix_timestamp(appdec_day,'yyyymmdd'), 'yyyy-mm-dd'), from_unixtime(unix_timestamp(app_day,'yyyymmdd'), 'yyyy-mm-dd')) > 30) and (not (rtf_state) IN ('D', 'C'))) and (biz_desc = '标准卡')) (type: boolean)
                // 表示对当前阶段的统计信息。例如，当前处理的数据行和数据量，这两个都是预估值
    			Statistics: Num rows: 18660 Data size: 5654095 Basic stats: COMPLETE Column stats: NONE
                // 表示在之前操作（TableScan）的结果集上进行数据的过滤
    			Filter Operator
    			// 表示filter Operator进行过滤时，所用的谓词，即where之后的过滤条件
                  predicate: (((datediff(from_unixtime(unix_timestamp(appdec_day,'yyyymmdd'), 'yyyy-mm-dd'), from_unixtime(unix_timestamp(app_day,'yyyymmdd'), 'yyyy-mm-dd')) > 30) and (not (rtf_state) IN ('D', 'C'))) and (biz_desc = '标准卡')) (type: boolean)
                  // 经过过滤后的数据量，同样也是预估值
    			  Statistics: Num rows: 1555 Data size: 471174 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                  // 表示需要投影的列，即筛选的列
                    expressions: '标准卡' (type: string)
                    outputColumnNames: biz_desc
                    Statistics: Num rows: 1555 Data size: 471174 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                    // 表示分组聚合使用的算法，这里是count(1)
                      aggregations: count(1)
                      // 表示分组的列，在该例子表示的是biz_desc
                      keys: biz_desc (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1555 Data size: 471174 Basic stats: COMPLETE Column stats: NONE
                      // 表示当前描述的是对之前结果聚会后的输出信息，这里表示Map端聚合后的输出信息
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        // 表示输出是否进行排序，+表示正序，-表示倒序
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 1555 Data size: 471174 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: bigint)
    		  // 表示当前描述的Reduce阶段执行的操作信息
    	      Reduce Operator Tree:
    	        Group By Operator
    	        // 指定分组聚合的算法
    	          aggregations: count(VALUE._col0)
    	          // 指定按哪些列进行分组
    	          keys: KEY._col0 (type: string)
    	          // 表示整个Hive执行过程的模式，complete表示所有的聚合操作都在Reduce中进行
    	          mode: mergepartial
    	          outputColumnNames: _col0, _col1
    	          Statistics: Num rows: 777 Data size: 235435 Basic stats: COMPLETE Column stats: NONE
    	          File Output Operator
    	          // 在File Output Operator中这个关键词表示文件输出的结果是否进行压缩，false表示不进行输出压缩
    	            compressed: false
    	            Statistics: Num rows: 777 Data size: 235435 Basic stats: COMPLETE Column stats: NONE
    	            table:
    	                input format: org.apache.hadoop.mapred.TextInputFormat
    	                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
    	                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
    					
    Stage: Stage-0
    	    Fetch Operator
    	      limit: -1
    	      Processor Tree:
    	        ListSink
    	        
###三、查看SQL数据输入依赖的信息

    3.1 
    explain dependency
    select
    t1.app_no
    from wcl_dwh.apt_card_card_cu t1
    inner join wcl_dwh.apt_card_acct_cu t2
    on t1.acct_no = t2.acct_no 
    and t1.data_date = t2.data_date
    and t1.data_date >= '20191229' and t1.data_date <= '20191231';
    ------------------------------------------------------------
    explain dependency
    select
    t1.app_no
    from wcl_dwh.apt_card_card_cu t1
    inner join wcl_dwh.apt_card_acct_cu t2
    on t1.acct_no = t2.acct_no 
    and t1.data_date = t2.data_date
    where t1.data_date >= '20191229' and t1.data_date <= '20191231';
    ------------------------------------------------------------
    通过上面的输出结果可以看到，其实上述的两个SQL并不等价，在内连接（inner join）中的连接条件中加入非等值的过滤条件后，
    并没有将内连接的左右两个表按照过滤条件进行过滤，内连接在执行时会多读取分区数据
    
    3.2
    explain dependency
    select
    t1.app_no
    from wcl_dwh.apt_card_card_cu t1
    left join wcl_dwh.apt_card_acct_cu t2
    on t1.acct_no = t2.acct_no 
    and t1.data_date = t2.data_date
    and t1.data_date >= '20191229' and t1.data_date <= '20191231';
    ------------------------------------------------------------
    explain dependency
    select
    t1.app_no
    from wcl_dwh.apt_card_card_cu t1
    left join wcl_dwh.apt_card_acct_cu t2
    on t1.acct_no = t2.acct_no 
    and t1.data_date = t2.data_date
    and t2.data_date >= '20191229' and t2.data_date <= '20191231';
    ------------------------------------------------------------
    可以看到，对左外连接在连接条件中加入非等值过滤的条件，如果过滤条件是作用于右表（b表）有起到过滤的效果，则右表只要扫描两个分区即
    可，但是左表（a表）会进行全表扫描。如果过滤条件是针对左表，则完全没有起到过滤的作用，那么两个表将进行全表扫描。这时的情况就如同全外
    连接一样都需要对两个数据进行全表扫描。
    
###四、查看SQL操作涉及的相关权限信息

    explain authorization
    select variance(credit_limit) from wcl_dwh.dwd_card_acct_cu;
    
###五、查看SQL的向量化描述信息

    set hive.vectorized.execution.enabled=true;
    explain vectorization expression
    
###六、带普通函数/操作符SQL的执行计划解读

    与二、具体执行计划解读大致相同，只有Map阶段
    
###七、带聚合函数的SQL执行计划解读

    与二、具体执行计划解读一致

###八、在Map和Reduce阶段聚合的SQL执行计划解读

    set hive.map.aggr=true; --其实默认是开启的，若看要区别需关闭后进行比对执行计划的差异
    与二、具体执行计划解读一致
    
###九、高级分组聚合执行计划解读

    **在使用高级分组聚合的语法时，要注意Hive是否开启了向量模式**

    GROUPING SETS、cube和rollup
    
    首先先理清三者的具体使用场景
    
    GROUPING SETS：
    SELECT
    acct_cd,acct_desc,count(1)
    from wcl_dwh.ads_umkt_acct 
    GROUP BY acct_desc,acct_cd
    GROUPING SETS(acct_cd,acct_desc);   --耗时16.91s
    ---------等价于------------
    SELECT null as a,t1.acct_desc as b,count(1) as c,1 AS GROUPING__ID from wcl_dwh.ads_umkt_acct t1 GROUP BY t1.acct_desc
    UNION all  --耗时54.11s
    select t2.acct_cd as a,null as b,count(1) as c,2 AS GROUPING__ID from wcl_dwh.ads_umkt_acct t2 GROUP BY t2.acct_cd;
                   
    cube：
    先看代码：
    
    select 
        if(grouping(a)=1, 'ALL', a) a,
        if(grouping(b)=1, 'ALL', b) b,
        count(1)
    from my_table
    group by
        cube(a, b)
    ---------等价于------------
    select 'ALL' a, 'ALL' b, count(1) from my_table # 整体进行聚合
    union all
    select a, 'ALL' b, count(1) from my_table group by a # a 为维度聚合
    union all
    select 'ALL' a, b, count(1) from my_table group by b # b 为维度聚合
    union all
    select a, b, count(1) from my_table group by a, b # a, b 两个维度聚合
    tips:
    1.grouping(a)=1 表示当不是以a为维度聚合的时候，也就是a会被合并的时候，返回true。此时用一个值来填充a，默认是NULL，这里我们用了更有意义的"ALL"字符串。
    2.当要聚合的维度很多时，用cube的计算量会非常大。聚合次数指数级增长。所以不要在cube里放太多字段。
    
    rollup：
    select 
        if(grouping(a)=1, 'ALL', a) a,
        if(grouping(b)=1, 'ALL', b) b,
        count(1)
    from my_table
    group by
        rollup(a, b)
    ---------等价于------------
    select 'ALL' a, 'ALL' b, count(1) from my_table # 整体进行聚合
    union all
    select a, 'ALL' b, count(1) from my_table group by a # a 为维度聚合
    union all
    select a, b, count(1) from my_table group by a, b # a, b 两个维度聚合
    tips:
    和cube函数的区别是，cube会把括号里面的所有字段进行组合，而rollup只会“递进”地聚合括号里的字段。
    
    如果使用该高级分组聚合的语句处理的基表，在数据量很大的情况下容易导致Map或者Reduce任务因硬件资源不足而崩溃。Hive中使用
    hive.new.job.grouping.set.cardinality配置项来应对上面可能出现的问题，如果SQL语句中处理的分组聚合情况超过该配置项指定的值，默认值（30），则会创建一个新的作业来处理该配置项的情况
    
    

    
    	 