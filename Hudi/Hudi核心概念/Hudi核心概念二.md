##Hudi核心概念二

###一、原语系列

    1.时间轴：
         Hudi维护一条包含在不同的即时时间所有对数据集操作的时间轴，从而提供，从不同时间点出发得到不同的视图下的数据集
        
      ·操作类型 : 对数据集执行的操作类型
      
            COMMITS - 一次提交表示将一组记录原子写入到数据集中。        
            CLEANS - 删除数据集中不再需要的旧文件版本的后台活动。        
            DELTA_COMMIT - 增量提交是指将一批记录原子写入到MergeOnRead存储类型的数据集中，其中一些/所有数据都可以只写到增量日志中。        
            COMPACTION - 协调Hudi中差异数据结构的后台活动，例如：将更新从基于行的日志文件变成列格式。在内部，压缩表现为时间轴上的特殊提交。        
            ROLLBACK - 表示提交/增量提交不成功且已回滚，删除在写入过程中产生的所有部分文件。       
            SAVEPOINT - 将某些文件组标记为"已保存"，以便清理程序不会将其删除。在发生灾难/数据恢复的情况下，它有助于将数据集还原到时间轴上的某个点。
        
      ·即时时间 : 即时时间通常是一个时间戳(例如：20190117010349)，该时间戳按操作开始时间的顺序单调增加。
      
      ·状态 : 即时的状态
      
            REQUESTED - 表示已调度但尚未启动的操作。            
            INFLIGHT - 表示当前正在执行该操作。           
            COMPLETED - 表示在时间轴上完成了该操作。
            
###二、文件组织

    1.Hudi将DFS上的数据集组织到基本路径下的目录结构中。数据集分为多个分区，这些分区是包含该分区的数据文件的文件夹，这与Hive表非常相似。每个分区被相对于基本路径的特定分区路径区分开来。
    2.在每个分区内，文件被组织为文件组，由文件id唯一标识。每个文件组包含多个文件切片，其中每个切片包含在某个提交/压缩即时时间生成的基本列文件（*.parquet）以及一组日志文件（*.log*），该文件包含自生成基本文件以来对基本文件的插入/更新。
    3.Hudi通过索引机制将给定的hoodie键（记录键+分区路径）映射到文件组，从而提供了高效的Upsert。一旦将记录的第一个版本写入文件，记录键和文件组/文件id之间的映射就永远不会改变。
    
###三、存储类型和视图

    Hudi存储类型定义了如何在DFS上对数据进行索引和布局以及如何在这种组织之上实现上述原语和时间轴活动（即如何写入数据）。
    反过来，视图定义了基础数据如何暴露给查询（即如何读取数据）。
    
    3.1 存储类型
    
        存储类型	            支持的视图
        写时复制(COW)	    读优化 + 增量
        读时合并(MOR)	    读优化 + 增量 + 近实时
        
        ·写时复制 : 仅使用列文件格式（例如parquet）存储数据。通过在写入过程中执行同步合并以更新版本并重写文件。（有利于读取繁重的分析工作）
        ·读时合并 : 使用列式（例如parquet）+ 基于行（例如avro）的文件格式组合来存储数据。更新记录到增量文件中，然后进行同步或异步压缩以生成列文件的新版本。
        
        存储类型之间的权衡：
        
        权衡	            写时复制	                读时合并
        数据延迟	        更高	                    更低
        更新代价(I/O)	更高（重写整个parquet文件）	更低（追加到增量日志）
        Parquet文件大小	更小（高更新代价（I/o））	更大（低更新代价）
        写放大	        更高	                     更低（取决于压缩策略）
        
    3.2 视图
    
        ·读优化视图 : 在此视图上的查询将查看给定提交或压缩操作中数据集的最新快照。该视图仅将最新文件切片中的基本/列文件暴露给查询，并保证与非Hudi列式数据集相比，具有相同的列式查询性能。
        
        ·增量视图 : 对该视图的查询只能看到从某个提交/压缩后写入数据集的新数据。该视图有效地提供了更改流，来支持增量数据管道。
              _ro: 更新原始数据
              _rt: 全量最新数据
                    
        ·实时视图 : 在此视图上的查询将查看某个增量提交操作中数据集的最新快照。该视图通过动态合并最新的基本文件(例如parquet)和增量文件(例如avro)来提供近实时数据集（几分钟的延迟）。