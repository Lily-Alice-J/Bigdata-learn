##Hudi核心概念三

###一、写入 Hudi 数据集（DeltaStreamer/Spark/Flink）

    ·UPSERT（插入更新） ：这是默认操作，在该操作中，通过查找索引，首先将输入记录标记为插入或更新。
    在运行启发式方法以确定如何最好地将这些记录放到存储上，如优化文件大小之类后，这些记录最终会被写入。
    对于诸如数据库更改捕获之类的用例，建议该操作，因为输入几乎肯定包含更新。
    
    ·INSERT（插入） ：就使用启发式方法确定文件大小而言，此操作与插入更新（UPSERT）非常相似，但此操作完全跳过了索引查找步骤。
    因此，对于日志重复数据删除等用例（结合下面提到的过滤重复项的选项），它可以比插入更新快得多。
    插入也适用于这种用例，这种情况数据集可以允许重复项，但只需要Hudi的事务写/增量提取/存储管理功能。
    
    ·BULK_INSERT（批插入） ：插入更新和插入操作都将输入记录保存在内存中，以加快存储优化启发式计算的速度（以及其它未提及的方面）。
    所以对Hudi数据集进行初始加载/引导时这两种操作会很低效。批量插入提供与插入相同的语义，但同时实现了基于排序的数据写入算法，
    该算法可以很好地扩展数百TB的初始负载。但是，相比于插入和插入更新能保证文件大小，批插入在调整文件大小上只能尽力而为。
    
    
###二、查询 Hudi 数据集（Hive/Spark/Presto/Flink）

![image](https://github.com/Tandoy/Bigdata-learn/blob/master/Hudi/images/%E6%9F%A5%E8%AF%A2Hudi%E6%95%B0%E6%8D%AE%E9%9B%86.PNG)




    