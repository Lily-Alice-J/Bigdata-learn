1.Spark处理数据流程、并行度决定机制

2.SparkSQL解析SQL的详细流程、hash广播底层实现

3.Spark shuffle、shuffle文件

4.groupByKey、reduceByKey、aggregateByKey、combineByKey区别

5.repartition和coalesce区别

6.Spark内存管理模型

7.Spark中能够进行下推的算子和不能进行下推的算子有哪些？谓词下推？映射（project）下推？

8.数仓数据的存储格式（parquet+snappy），为什么使用parquet、parquet特性、底层结构？parquet事务？parquet进行字段的新增或删除，如何进行数据的历史数据中字段的新增或删除（非重跑数据）？

9.Flink watermark

10.HDFS写数据流程、fsimage作用、如何区分HDFS热数据和冷数据

11.数据倾斜（Spark、Hive、HBase）

12.MapReduce原理，map数、reduce数决定机制

13.说一下 map join 与 reduce join

14.spark和hive的区别

15.udf、udtf、udaf，集成的类、接口，怎么写

16.hive文件存储格式，对比

17.parquet文件和orc文件区别

18.hive内外表区别

19.hive执行的job数是怎么确定的

20.窗口函数中几个rank函数的区别

21.cube、grouping sets、grouping__id

22.你进行过hive sql到spark sql的任务迁移吗？有没有遇到语法/sql语句兼容性问题？

23.如何建设数仓，如何构建主题域

24.缓慢变化维 几种处理方式

25.什么是维度建模，星型模型与雪花模型的区别

26.数仓建设以及分层的好处

27.怎么做数据质量，怎么保证及时性和准确性

28.维度表和事实表？

29.如何数据治理？

30.谈谈你对数据仓库、数据中台、数据湖的理解？

31.做过实时数仓吗，讲一下

32.数仓建模方法，你公司用的是什么建模方法？为什么采用这种建模方法？

33.Yarn client和Yarn cluster区别？

34.提交到Yarn上的应用如Spark与Yarn的交互流程？

35.HBase架构、row key和列族设计及注意事项？为什么使用LSM树（与传统的RDBMS如mysql的B+树对比）？

36.HBase适合读多写少还是写多读少的场景，为什么？HBase二级索引？HBase小文件过多的原因？

37.Phoenix查询HBase数据把HBase搞崩的问题有没有遇到过？可能是哪些原因导致的？

38.Kafka高可用、高性能的原理？使用过哪些版本的Kafka，有没有遇到一些bug，怎么导致的，如何解决？Kafka数据顺序性问题？

39.Kafka重分区问题，如何尽可能避免重分区问题？

40.Zookeeper作用，服务节点动态上下线和负载均衡怎么实现的？zookeeper选主和在其他集群（如Hadoop HA）中是如何进行选主的？zookeeper分布式锁、监听（watcher）机制

41.用过哪些任务调度工具？了解azkaban、airflow吗？

42.Redis数据结构、分布式锁。数据发生更新、是先更新DB再更新redis缓存还是反过来，怎么处理以及为什么？

43.mysql事务

44.红黑树和平衡二叉树区别

45.JVM结构、堆、垃圾回收算法、垃圾回收器

46.Java基本数据类型、引用类型、实现线程的方式？对于两个线程a和b，如何确保在线程a执行完毕后才能执行线程b？

47.Java基本类型和封装类型区别，在JVM中的分布？

48.Scala中的隐式转换、object和class区别、Scala集合和Java如何互转？

49.leetcode系列题，如股票买卖利润最大化问题？

50.SQL列转行、行转列、连续N天登录等？

51.跨数据中心/机房数据迁移方案？

52.大数据集群运维事项（Hadoop集群节点、配置，HBase集群运维等）

53.为什么离职？什么时间能入职？

54.对于将来的职业规划？

55.你有什么想问我的吗？

[大数据面试题V3.1](https://mp.weixin.qq.com/s/Yc4C-rnsBdI4gTZMS0zHnA)