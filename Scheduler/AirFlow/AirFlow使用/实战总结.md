#注意事项

1.airflow采用python解析HQL

  1.1 传参问题：可将复杂sql拆分多行 " \进行分割，然后{0}.format()形式进行传参
              也可采用'%s' %etl_date进行传参

  1.2 python解析问题：

      1.2.1 首先sql中不能存在注释

      1.2.2 存在严格缩进写法不然无法解析

      1.2.3 注意sql中所有双引号改为单引号不然解析报错

      1.2.4 建议行尾" \分割符书写时每行自动空格避免解析报错
      
      1.2.5 需要回溯历史数据时，跑批日期不应设置为：datetime.now()，它默认是读取服务器同步时间
            而不是实际的回溯跑批日期，而应设置为：
          T:
            etl_date="{{macros.ds_format(ds,'%Y-%m-%d','%Y%m%d')}}"
            etl_mth="{{macros.ds_format(ds,'%Y-%m-%d','%Y')}}"+"{{macros.ds_format(ds,'%Y-%m-%d','%m')}}"
          T-2
            etl_date="{{macros.ds_format(macros.ds_add(ds,-2),'%Y-%m-%d','%Y%m%d')}}"
            etl_mth="{{macros.ds_format(macros.ds_add(ds,-2),'%Y-%m-%d','%Y')}}"+"{{macros.ds_format(ds,'%Y-%m-%d','%m')}}"
  
2.airflow指定hive参数问题
  2.1 由于业务场景需要常常需要进行复杂HQL的书写，但由于测试环境与生产环境的差异往往跑批过程中出现OOM、数据倾斜等问题
      这是便需要设定hive参数进行调优处理。在hue中可直接书写，但airflow需在dag中进行指定
      
      sqlccdbiz = SQL_stg_card_ccdbiz_cu()
      stg_card_ccdbiz_cu = HiveOperator(
            task_id = "stg_card_ccdbiz_cu",
            hql = sqlccdbiz.sqlstg_ccdbiz,
            hiveconfs={'mapreduce.map.java.opts':'-Xmx3072m','hive.auto.convert.join':'false'},
            hive_cli_conn_id = 'hive',
            dag = dag
      	)
3.airflow参数
  3.1 retries：是指任务失败后重试次数
  3.2 retry_delay：重试间隔
  若存在复杂业务HQL，自行预估会影响集群yarn分配资源的大小以及时长，可设置重试次数以及重试间隔