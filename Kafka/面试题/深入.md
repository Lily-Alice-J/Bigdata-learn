2.1、创建或者删除topic时，Kafka底层执行了哪些逻辑？

    以创建topic为例，比如我们执行如下命令，创建了一个叫做csdn的分区数为1，副本数为3的topic。
    bin/kafka-topics.sh --zookeeper node:2181 --create \
    --replication-factor 3 --partitions 1 --topic csdn
    这行命令，在kafka底层需要经过三个步骤来处理：
    1. 在zookeeper中的/brokers/topics节点下创建一个新的topic节点，如：/brokers/topics/csdn；
    2. 然后会触发Controller的监听程序；
    3. 最后kafka Controller负责topic的创建工作，并更新metadata cache，到这里topic创建完成。

2.2、你了解Kafka的日志目录结构吗？

    1. 每个 Topic 都可以分为一个或多个 Partition，Topic其实是比较抽象的概念，但是 Partition是比较具体的东西；
    2. 其实Partition 在服务器上的表现形式就是一个一个的文件夹，由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment；
    3. 每组 Segment 文件又包含 .index 文件、.log 文件、.timeindex 文件（早期版本中没有）三个文件。.log和.index文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，csdn这个topic有2个分区，则其对应的文件夹为csdn-0,csdn-1；
    4. log 文件就是实际存储 Message 的地方，而 index 和 timeindex 文件为索引文件，用于检索消息

2.3、Kafka中需要用到选举吗？对应选举策略是什么？

    一共有两处需要用到选举，首先是partition的leader，用到的选举策略是ISR；然后是kafka Controller，用先到先得的选举策略。

2.4、追问，聊聊你对ISR的了解？

    ISR就是kafka的副本同步队列，全称是In-Sync Replicas。ISR 中包括 Leader 和 Follower。如果 Leader 进程挂掉，会在 ISR 队列中选择一个服务作为新的 Leader。有 replica.lag.max.messages（延 迟条数）和replica.lag.time.max.ms（延迟时间）两个参数决定一台服务是否可以加入 ISR 副 本队列，在 0.10 版本移除了 replica.lag.max.messages 参数，防止服务频繁的进去队列。
    任意一个维度超过阈值都会把 Follower 剔除出 ISR，存入 OSR（Outof-Sync Replicas） 列表，新加入的 Follower 也会先存放在 OSR 中。

2.5、聊聊Kafka分区分配策略？

    在 Kafka 内部存在三种默认的分区分配策略：Range ， RoundRobin以及0.11.x版本引入的Sticky。Range 是默认策略。Range 是对每个 Topic 而言的（即一个 Topic 一个 Topic 分），首先 对同一个 Topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用 Partitions 分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。
    三种分区分配策略详见文章：深入分析Kafka架构（三）：消费者消费方式、分区分配策略（Range分配策略、RoundRobin分配策略、Sticky分配策略）、offset维护
    文中对三种分区分配策略举例并进行了非常详细的对比，值得一看。

2.6、当Kafka消息数据出现了积压，应该怎么处理？

    数据积压主要可以从两个角度去分析：
    1. 如果是 Kafka 消费能力不足，则可以考虑增加 Topic 的分区数，并且同时提升消费 组的消费者数量，消费者数=分区数。（两者缺一不可）
    2. 如果是下游的数据处理不及时：提高每批次拉取的数量。如果是因为批次拉取数据过少（拉取 数据/处理时间<生产速度），也会使处理的数据小于生产的数据，造成数据积压。

2.7、Kafka是怎么实现Exactly Once的？

    在实际情况下，我们对于某些比较重要的消息，需要保证exactly once语义，也就是保证每条消息被发送且仅被发送一次，不能重复。在0.11版本之后，Kafka引入了幂等性机制（idempotent），配合acks = -1时的at least once语义，实现了producer到broker的exactly once语义。
    idempotent + at least once = exactly once
    使用时，只需将enable.idempotence属性设置为true，kafka自动将acks属性设为-1。

2.8、追问、谈谈你对Kafka幂等性的理解？

    Producer的幂等性指的是当发送同一条消息时，数据在 Server 端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：
    1. 只能保证 Producer 在单个会话内不丟不重，如果 Producer 出现意外挂掉再重启是 无法保证的。因为幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重。
    2. 幂等性不能跨多个 Topic-Partition，只能保证单个 Partition 内的幂等性，当涉及多个Topic-Partition 时，这中间的状态并没有同步。

2.9、你对Kafka事务了解多少？

    Kafka是在0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基 础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。
    1. Producer 事务：
    为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer 获得的 PID 和 Transaction ID 绑定。这样当 Producer 重启后就可以通过正在进行的 Transaction ID 获得原来的 PID。
    为了管理 Transaction，Kafka 引入了一个新的组件 Transaction Coordinator。Producer 就 是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于 事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。
    2. Consumer 事务：上述事务机制主要是从Producer方面考虑，对于 Consumer 而言，事务的保证就会相对较弱，尤其时无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过offset访问任意信息，而且不同的 Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。

2.10、Kafka怎么实现如此高的读写效率？

    1. 首先kafka本身是分布式集群，同时采用了分区技术，具有较高的并发度；
    2. 顺序写入磁盘，Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。
    官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这 与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。


3. 零拷贝技术
