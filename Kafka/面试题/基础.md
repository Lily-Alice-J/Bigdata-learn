1.1、你们Kafka集群的硬盘一共多大？有多少台机器？日志保存多久？用什么监控的？

    这里考察应试者对kafka实际生产部署的能力，也是为了验证能力的真实程度，如果这个都答不好，那可能就不会再继续下去了。
    一般企业判断这些指标有一个标准：
    集群硬盘大小：每天的数据量/70%*日志保存天数；
    机器数量：Kafka 机器数量=2*（峰值生产速度*副本数/100）+1；
    日志保存时间：可以回答保存7天；
    监控Kafka：一般公司有自己开发的监控器，或者cdh配套的监控器，另外还有一些开源的监控器：kafkaeagle、KafkaMonitor、KafkaManager。

1.2、Kafka分区数、副本数和topic数量多少比较合适？

    首先要知道分区数并不是越多越好，一般分区数不要超过集群机器数量。分区数越多占用内存越大 （ISR 等），一个节点集中的分区也就越多，当它宕机的时候，对系统的影响也就越大。
    分区数一般设置为：3-10 个。
    副本数一般设置为：2-3个。
    topic数量需要根据日志类型来定，一般有多少个日志类型就定多少个topic，不过也有对日志类型进行合并的。

1.3、Kafka中的HW、LEO、ISR、AR分别是什么意思？

    LEO：每个副本的最后一条消息的offset
    HW：一个分区中所有副本最小的offset
    ISR：与leader保持同步的follower集合
    AR：分区的所有副本

1.4、Kafka中的消息有序吗？怎么实现的？

    kafka无法保证整个topic多个分区有序，但是由于每个分区（partition）内，每条消息都有一个offset，故可以保证分区内有序。

1.5、topic的分区数可以增加或减少吗？为什么？

    topic的分区数只能增加不能减少，因为减少掉的分区也就是被删除的分区的数据难以处理。
    增加topic命令如下：
    bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter \
    --topic topic-config --partitions 3
    关于topic还有一个面试点要知道：消费者组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据。

1.6、你知道kafka是怎么维护offset的吗？

    1.维护offset的原因：由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。
    2. 维护offset的方式：Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为**__consumer_offsets**。
    3.需要掌握的关于offset的常识：消费者提交消费位移时提交的是当前消费到的最新消息的offset+1而不是offset。

1.7、你们是怎么对Kafka进行压测的？

    Kafka官方自带了压力测试脚本（kafka-consumer-perf-test.sh、kafka-producer-perf-test.sh）， Kafka 压测时，可以查看到哪个地方出现了瓶颈（CPU，内存，网络 IO），一般都是网络 IO 达到瓶颈。
